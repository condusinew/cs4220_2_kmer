{"cells":[{"cell_type":"markdown","metadata":{"id":"yppvRz2vUlAG"},"source":["# CS4220 Project 2 - Pathogen Detection\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oLejWacMUlAH","outputId":"05e226e2-082c-4ecb-95ac-978f5f2217eb"},"outputs":[],"source":["# import packages\n","import numpy as np\n","import pandas as pd\n","import timeit\n","import time\n","from sklearn import preprocessing\n","import csv\n","from joblib import dump, load\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import preprocessing\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle as pkl\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load dictionary that maps k-mer to their corresponding index.\n","# A k-mer and its reverse complement are mapped to the same index.\n","# We use k=6 here as an example.\n","\n","import json\n","\n","with open(\"./training_data/8-mers.json\", 'r') as dict_file:\n","    canonical_kmer_dict = json.load(dict_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# We define a utility function here that turns sequences to their 8-mer profiles.\n","\n","def sequence_to_kmer_profile(sequence : str, k : int = 8):\n","    \"\"\"\n","    Return the k-mer profile of the input sequence (string)\n","    \"\"\"\n","    res = np.zeros(len(set(canonical_kmer_dict.values())))\n","    \n","    for i in range(len(sequence) - k + 1):\n","        k_mer = sequence[i:i + k]\n","        if k_mer in canonical_kmer_dict:\n","            res[canonical_kmer_dict[k_mer]] += 1\n","        else:\n","            res[-1] += 1\n","\n","    res /= np.sum(res)\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","\n","class CS4220Dataset(Dataset):\n","    def __init__(self, data_file, label_df=None, k=6, samples_index=None, kmer_profile_on_the_fly=False, dtype=np.float32):\n","        \"\"\"\n","        Dataset class to load large CS4220 sequence database.\n","\n","        Args:\n","            - data_file (`str`): Can either be a *.fasta file if the input is raw reads, or *.npy file\n","                                 if the input is k-mer profile.\n","            - label_df (`pd.DataFrame` or `None`): A dataframe with \"labels\" column indicating the label\n","                                                   of the data (must match with data_file), or `None` if there is\n","                                                   no label (in the case of test sets).\n","            - k (`int`): The lengt of k-mer. We use 6 in this project.\n","            - samples_index (`List` or `None`): list of indices of data we sample from the data file. You\n","                                                can use this if the dataset is very large and can't fit in memory.\n","                                                set this to `None` if you want to use all the data.\n","            - kmer_profile_on_the_fly (`bool`): If input data_file is raw reads and this set to `True`,\n","                                                we will build k-mer profile on the fly. This is helpful if you want to\n","                                                alter the input sequences during training, or the k-mer profile can't fit in memory.\n","                                                Otherwise, we build k-mer profile in advance, which will speed up the\n","                                                training process.\n","            - dtype: type to store the k-mer profile. You may use, for example, `np.float32` for better precision,\n","                     or `np.float16` for smaller memory usage. If loaded from \".npy\" file, it is always `np.float16`.\n","        \"\"\"\n","        self.data_file = data_file\n","\n","        if \".fasta\" in data_file or \".fa\" in data_file or \".fna\" in data_file:\n","            self.is_raw_reads = True\n","        elif \".npy\" in data_file:\n","            self.is_raw_reads = False\n","        else:\n","            raise TypeError(f\"The input file must be either a fasta file containing raw reads (.fasta, .fa, .fna) or a numpy file containing k-mer profiles (.npy).\")\n","\n","\n","        self.label_df = label_df\n","        self.kmer_profile_otf = kmer_profile_on_the_fly\n","\n","        # k-mer length, set to be 6.\n","        self.k = k\n","\n","        # the samples we take from the read dataset\n","        self.samples_index = samples_index\n","\n","        self.dtype = dtype\n","\n","        # Load the data and store in self.reads and self.labels\n","        self.X = []\n","        self.Y = []\n","        self._read_labels()\n","        self._read_data()\n","\n","\n","    def _read_labels(self):\n","        \"\"\"\n","        Read the labels and record them in self.labels.\n","        \"\"\"\n","        if self.label_df is None:\n","            self.Y = None\n","        elif self.samples_index is None:\n","            # Load the whole dataset\n","            self.Y = list(self.label_df[\"labels\"])\n","        else:\n","            # Load only the data corresponding to the sampled index\n","            self.Y = list(self.label_df.iloc[self.samples_index][\"labels\"])\n","\n","\n","    def _read_data(self):\n","        if self.is_raw_reads:\n","            # Read the fasta file\n","            with open(self.data_file, 'r') as fasta_file:\n","                lines = fasta_file.readlines()\n","\n","            read_range = self.samples_index if self.samples_index is not None else range(int(len(lines) / 2))\n","            if not self.kmer_profile_otf:\n","                self.X = np.zeros(\n","                    (len(read_range), len(set(canonical_kmer_dict.values()))),\n","                    dtype=self.dtype\n","                )\n","\n","            for i, j in enumerate(tqdm(read_range, desc=f\"Parsing fasta file {self.data_file}\")):\n","                read = lines[j * 2 + 1].strip()\n","                if self.kmer_profile_otf:\n","                    # If chose to do k-mer profiling on the fly, simply store the reads\n","                    self.X.append(read)\n","                else:\n","                    # Otherwise, do k-mer profiling during training/testing, cost more time during training/testing\n","                    self.X[i, :] = sequence_to_kmer_profile(read, self.k)\n","        else:\n","            # Read the .npy file, and load the numpy matrix\n","            # Each row corresponds to a read, and each column corresponds to a k-mer (see training_data/6-mers.txt).\n","            self.X = np.load(self.data_file)\n","            if self.samples_index is not None:\n","                self.X = self.X[self.samples_index, :]\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        If you are using pytorch, this function helps taking data points during each epoch\n","        of your training.\n","        \"\"\"\n","        x = self.X[idx]\n","        if self.kmer_profile_otf:\n","            read_tensor = torch.tensor(sequence_to_kmer_profile(x, self.k), dtype=self.dtype)\n","        else:\n","            read_tensor = torch.tensor(x)\n","\n","        label = self.Y[idx] if self.Y is not None else None\n","        return read_tensor, label\n","\n","\n","#INSERT PATIENT INPUT PATH HERE\n","input_file_path = './training_data/patient[i].npy'\n","\n","label_df = pd.read_csv('./training_data/train_labels.csv')\n","dataset = CS4220Dataset(input_file_path, label_df, k=8, samples_index=samples_index)"]},{"cell_type":"markdown","metadata":{"id":"KwEbgy3SUlAI"},"source":["## Load Groups and Assigning Groups\n","First, we create labels with the groups decided by Jaccard index."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["[['corynebacterium_diphtheriae',\n","  'corynebacterium_striatum',\n","  'corynebacterium_ulcerans'],\n"," ['acinetobacter_baumannii',\n","  'enterococcus_faecium',\n","  'legionella_pneumophila',\n","  'listeria_monocytogenes',\n","  'staphylococcus_aureus',\n","  'staphylococcus_epidermidis',\n","  'staphylococcus_haemolyticus',\n","  'staphylococcus_pseudintermedius',\n","  'staphylococcus_pyogenes',\n","  'streptococcus_agalactiae',\n","  'streptococcus_anginosus',\n","  'streptococcus_mitis',\n","  'streptococcus_pneumoniae',\n","  'streptococcus_salivarius',\n","  'streptococcus_suis'],\n"," ['mycobacterium_tuberculosis',\n","  'mycobacterium_ulcerans',\n","  'pseudomonas_aeruginosa',\n","  'stenotrophomonas_maltophilia'],\n"," ['escherichia_coli',\n","  'klebsiella_michiganensis',\n","  'klebsiella_pneumoniae',\n","  'salmonella_enterica_typhimurium',\n","  'serratia_liquefaciens',\n","  'vibrio_parahaemolyticus',\n","  'yersinia_enterocolitica'],\n"," ['neisseria_gonorrhoeae', 'neisseria_lactamica']]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["with open(\"groups\"+str(8)+\".csv\", \"r\") as file:\n","    reader = csv.reader(file)\n","    groups_loaded = [row for row in reader]\n","\n","groups_loaded"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["species_name\n","homo_sapiens                       400027\n","burkholderia_pseudomallei            3540\n","pseudomonas_aeruginosa               3111\n","mycobacterium_ulcerans               3024\n","klebsiella_michiganensis             3010\n","bacillus_cereus                      2889\n","klebsiella_pneumoniae                2799\n","escherichia_coli                     2760\n","serratia_liquefaciens                2685\n","vibrio_parahaemolyticus              2572\n","stenotrophomonas_maltophilia         2524\n","salmonella_enterica_typhimurium      2491\n","yersinia_enterocolitica              2271\n","mycobacterium_tuberculosis           2173\n","clostridioides_difficile             2020\n","acinetobacter_baumannii              2005\n","legionella_pneumophila               1674\n","listeria_monocytogenes               1487\n","enterococcus_faecium                 1467\n","corynebacterium_striatum             1437\n","staphylococcus_aureus                1392\n","staphylococcus_haemolyticus          1298\n","staphylococcus_pseudintermedius      1254\n","corynebacterium_diphtheriae          1246\n","staphylococcus_epidermidis           1242\n","micrococcus_luteus                   1236\n","corynebacterium_ulcerans             1236\n","streptococcus_salivarius             1107\n","neisseria_lactamica                  1098\n","neisseria_gonorrhoeae                1091\n","streptococcus_suis                   1080\n","streptococcus_pneumoniae             1074\n","streptococcus_agalactiae             1047\n","streptococcus_anginosus               989\n","streptococcus_mitis                   972\n","staphylococcus_pyogenes               874\n","campylobacter_jejuni                  822\n","Name: count, dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#make labels\n","label_df = pd.read_csv('./training_data/train_labels.csv')\n","label_df['species_name'].value_counts()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def assign_group(species, species_list, group_id):\n","    if species in species_list:\n","        return group_id\n","    return species\n","\n","#TO APPEND TO\n","label_groups = {}\n","species_to_keep = {}\n","master_labels = label_df.copy()\n","grouped_labels = label_df.copy()\n","\n","#FOR GROUP 1\n","species_to_keep[1] = ['corynebacterium_diphtheriae',\n","'corynebacterium_striatum',\n","'corynebacterium_ulcerans']\n","\n","#FOR GROUP 2\n","species_to_keep[2] = ['acinetobacter_baumannii',\n","'enterococcus_faecium',\n","'legionella_pneumophila',\n","'listeria_monocytogenes',\n","'staphylococcus_aureus',\n","'staphylococcus_epidermidis',\n","'staphylococcus_haemolyticus',\n","'staphylococcus_pseudintermedius',\n","'staphylococcus_pyogenes',\n","'streptococcus_agalactiae',\n","'streptococcus_anginosus',\n","'streptococcus_mitis',\n","'streptococcus_pneumoniae',\n","'streptococcus_salivarius',\n","'streptococcus_suis']\n","\n","#FOR GROUP 3\n","species_to_keep[3] = ['mycobacterium_tuberculosis',\n","  'mycobacterium_ulcerans',\n","  'pseudomonas_aeruginosa',\n","  'stenotrophomonas_maltophilia']\n","\n","#FOR GROUP 4\n","species_to_keep[4] = ['escherichia_coli',\n","  'klebsiella_michiganensis',\n","  'klebsiella_pneumoniae',\n","  'salmonella_enterica_typhimurium',\n","  'serratia_liquefaciens',\n","  'vibrio_parahaemolyticus',\n","  'yersinia_enterocolitica']\n","\n","#FOR GROUP 5\n","species_to_keep[5] = ['neisseria_gonorrhoeae', 'neisseria_lactamica']\n","\n","species_to_keep[6] = ['homo_sapiens']\n","\n","#REPLACING OUTGROUP SPECIES W 'Other'\n","for i in range(1,7):\n","    label_groups[i] = label_df.copy()\n","\n","    #keep label if in species to keep\n","    label_groups[i]['species_name'] = label_groups[i]['species_name'].apply(lambda x: x if x in species_to_keep[i] else 'Other')\n","\n","    #replace w group # if in species to keep \n","    grouped_labels['species_name'] = grouped_labels['species_name'].apply(lambda x: assign_group(x, species_to_keep[i], str(i)))\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#HUMAN\n","lehumans = preprocessing.LabelEncoder()\n","lehumans.fit(label_groups[6]['species_name'].unique())\n","y_index = lehumans.transform(label_groups[6]['species_name'].values)\n","label_groups[6]['labels'] = y_index\n","\n","#GROUPED, FIRST LAYER\n","le = preprocessing.LabelEncoder()\n","le.fit(grouped_labels['species_name'].unique())\n","y_index = le.transform(grouped_labels['species_name'].values)\n","grouped_labels['labels'] = y_index\n","\n","#MASTER GROUPS\n","masle = preprocessing.LabelEncoder()\n","masle.fit(master_labels['species_name'].unique())\n","y_index = masle.transform(master_labels['species_name'].values)\n","master_labels['labels'] = y_index\n","\n","#GROUP 1\n","le1 = preprocessing.LabelEncoder()\n","le1.fit(label_groups[1]['species_name'].unique())\n","y_index = le1.transform(label_groups[1]['species_name'].values)\n","label_groups[1]['labels'] = y_index\n","\n","#GROUP 2\n","le2 = preprocessing.LabelEncoder()\n","le2.fit(label_groups[2]['species_name'].unique())\n","y_index = le2.transform(label_groups[2]['species_name'].values)\n","label_groups[2]['labels'] = y_index\n","\n","#GROUP 3\n","le3 = preprocessing.LabelEncoder()\n","le3.fit(label_groups[3]['species_name'].unique())\n","y_index = le3.transform(label_groups[3]['species_name'].values)\n","label_groups[3]['labels'] = y_index\n","\n","#GROUP 4\n","le4 = preprocessing.LabelEncoder()\n","le4.fit(label_groups[4]['species_name'].unique())\n","y_index = le4.transform(label_groups[4]['species_name'].values)\n","label_groups[4]['labels'] = y_index\n","\n","#GROUP 5\n","le5 = preprocessing.LabelEncoder()\n","le5.fit(label_groups[5]['species_name'].unique())\n","y_index = le5.transform(label_groups[5]['species_name'].values)\n","label_groups[5]['labels'] = y_index"]},{"cell_type":"markdown","metadata":{},"source":["# TRAINING MODEL FOR GROUP CLASSIFICATION \n","Loading models that have already been trained"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn import preprocessing"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["species_df = pd.read_csv('./all_species.csv')\n","pathogen_list = list(species_df[species_df['type'] == 'pathogen']['genome_name'])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#loading models\n","from joblib import dump, load\n","\n","rf_only = {}\n","rf = load('models/rf_humans.joblib')\n","rf_nonhumans_groups = load('models/rf_nonhumans_into_groups.joblib')\n","rf_only[1] = load('models/rf_group1.joblib')\n","rf_only[2] = load('models/rf_group2.joblib')\n","rf_only[3] = load('models/rf_group3.joblib')\n","rf_only[4] = load('models/rf_group4.joblib')\n","rf_only[5] = load('models/rf_group5.joblib')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#PREDICTIONS, FIRST LAYER - human vs nonhuman\n","def human_predict():\n","    y_humans_pred = rf.predict(df_test)\n","    y_humans_predprob = rf.predict_proba(df_test)\n","    df_test_df['human_predictions'] = y_humans_pred"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#PREDICTIONS, SECOND LAYER - genera and groupings\n","def grouping(threshold = 0.7):    \n","    subset_mask = df_test_df['human_predictions'] == 0\n","    feature_cols = list(range(0, 32897))\n","    subset = df_test_df.loc[subset_mask, feature_cols]\n","\n","    # predict\n","    '''if len(subset) == 0:\n","        continue'''\n","    y_groups_pred = rf_nonhumans_groups.predict(subset)\n","    y_groups_predprob = rf_nonhumans_groups.predict_proba(subset)\n","\n","    grouped_predictions = [\n","                le.inverse_transform([np.argmax(item)])[0] if np.max(item) >= threshold else 'homo_sapiens'\n","                for item in y_groups_predprob\n","            ]\n","\n","    # replace the original 'grouped_predictions' values in the subset\n","    df_test_df.loc[subset_mask, 'grouped_predictions'] = grouped_predictions"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"fqwtElwCUlAL"},"outputs":[],"source":["def jaccard_index_per_patient(patient_id, preds):\n","    df_true = pd.read_csv('test_data/patient{}_labels.csv'.format(patient_id))\n","    tp, fp, tp_fn = 0, 0, df_true['labels'].shape[0]\n","    # print('my predition(s) for patient {}:'.format(patient_id))\n","    # print(preds)\n","    # print('true pathogen')\n","    # print(df_true['labels'].values)\n","    # if don't predict any pathogen, it means there is only decoy in the test dataset (your prediction)\n","    if len(preds) == 0:\n","        preds = ['NONE']\n","    if len(df_true['labels']) == 0:\n","        df_true['labels'] = ['NONE']\n","        tp_fn = 1\n","\n","    for item in np.unique(preds):\n","        if item in df_true['labels'].values:\n","            tp += 1\n","        else:\n","            fp += 1\n","    #you have to predict all labels correctly, but you are penalized for any false positive\n","    return tp / (tp_fn + fp)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["#intialize\n","rf_list = [rf_nonhumans_groups, rf_only[1], rf_only[2], rf_only[3], rf_only[4], rf_only[5]]\n","le_list = [le, le1, le2, le3, le4, le5]\n","all_jaccard_index = []\n","results = []\n","from collections import Counter\n","\n","df_test_df = pd.DataFrame(dataset)\n","\n","#predict\n","human_predict()\n","grouping()\n","\n","df_test_for_loop = df_test_df.copy()\n","\n","#loops over to get predictions for groups 1-5 and replaces them in the df \n","for i in range(1, 6):\n","    rf_now = rf_list[i]\n","    le_now = le_list[i]\n","    \n","    # subset for each group i \n","    subset_mask = df_test_df['grouped_predictions'] == str(i)\n","    feature_cols = list(range(0, 32897))\n","    subset = df_test_df.loc[subset_mask, feature_cols]\n","\n","    # predict\n","    if len(subset) == 0:\n","        continue\n","\n","    y_preds = rf_now.predict(subset)\n","    y_predprob = rf_now.predict_proba(subset)\n","    \n","    y_preds_mapped = [\n","        le_now.inverse_transform([np.argmax(item)])[0] if np.max(item) >=  0.4 else 'homo_sapiens'\n","        for item in y_predprob]\n","\n","    #count occurrences of each label\n","    counts = Counter(y_preds_mapped)\n","\n","    #replace failed labels with 'homo_sapiens'\n","    y_preds_mapped = [\n","        label if counts[label] >= 6 else 'homo_sapiens'\n","        for label in y_preds_mapped\n","    ]\n","    # replace the original 'grouped_predictions' values in the subset\n","    df_test_for_loop.loc[subset_mask, 'grouped_predictions'] = y_preds_mapped\n","\n","\n","#get unique only and append\n","unique_predicts = df_test_for_loop[\"grouped_predictions\"].unique()\n","unique_predicts = [item for item in unique_predicts if item in pathogen_list]\n","\n","unique_predicts.to_csv('patient${i}.csv')"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patient_id</th>\n","      <th>ground_truth</th>\n","      <th>predictions</th>\n","      <th>jaccard_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[neisseria_gonorrhoeae]</td>\n","      <td>[neisseria_gonorrhoeae]</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[corynebacterium_ulcerans]</td>\n","      <td>[]</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[staphylococcus_aureus]</td>\n","      <td>[]</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[streptococcus_pneumoniae]</td>\n","      <td>[streptococcus_pneumoniae]</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[salmonella_enterica_typhimurium, clostridioid...</td>\n","      <td>[klebsiella_pneumoniae, campylobacter_jejuni]</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>[mycobacterium_tuberculosis, pseudomonas_aerug...</td>\n","      <td>[mycobacterium_ulcerans, neisseria_gonorrhoeae...</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>[klebsiella_pneumoniae]</td>\n","      <td>[klebsiella_michiganensis, streptococcus_agala...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>[staphylococcus_pyogenes, corynebacterium_diph...</td>\n","      <td>[clostridioides_difficile]</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>[burkholderia_pseudomallei, listeria_monocytog...</td>\n","      <td>[streptococcus_pneumoniae]</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   patient_id                                       ground_truth  \\\n","0           0                            [neisseria_gonorrhoeae]   \n","1           1                         [corynebacterium_ulcerans]   \n","2           2                            [staphylococcus_aureus]   \n","3           3                         [streptococcus_pneumoniae]   \n","4           4  [salmonella_enterica_typhimurium, clostridioid...   \n","5           5  [mycobacterium_tuberculosis, pseudomonas_aerug...   \n","6           6                            [klebsiella_pneumoniae]   \n","7           7  [staphylococcus_pyogenes, corynebacterium_diph...   \n","8           8  [burkholderia_pseudomallei, listeria_monocytog...   \n","9           9                                                 []   \n","\n","                                         predictions  jaccard_index  \n","0                            [neisseria_gonorrhoeae]            1.0  \n","1                                                 []            0.0  \n","2                                                 []            0.0  \n","3                         [streptococcus_pneumoniae]            1.0  \n","4      [klebsiella_pneumoniae, campylobacter_jejuni]            0.0  \n","5  [mycobacterium_ulcerans, neisseria_gonorrhoeae...            0.2  \n","6  [klebsiella_michiganensis, streptococcus_agala...            0.0  \n","7                         [clostridioides_difficile]            0.0  \n","8                         [streptococcus_pneumoniae]            0.0  \n","9                                                 []            1.0  "]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(results)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["results_df = pd.DataFrame(results)\n","\n","results_df.to_csv('JI_results_forRF.csv', index=False)  \n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["0.32"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["results_df[\"jaccard_index\"].mean()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"cs4220","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
